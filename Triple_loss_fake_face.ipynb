{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Triple_loss_fake_face.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMVdiMVMxagMTJWYeC5CAvW",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RVijayChiranjithReddy/Fake_face_detection/blob/main/Triple_loss_fake_face.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jdxdjr9P064n"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from keras.layers import *\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.models import *\n",
        "from keras.optimizers import *\n",
        "import keras.backend as K\n",
        "import dlib\n",
        "from PIL import Image\n",
        "from skimage import io\n",
        "import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gGD_IwX08Er",
        "outputId": "0714bfbb-8212-4660-d2a5-caca156acd3c"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive',force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-_jE_P21BJV"
      },
      "source": [
        "\t\n",
        "from keras.applications.vgg16 import VGG16\n",
        "model = VGG16(weights=None)\n",
        "trip = Model(model.input,model.layers[-5].output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnkQfhzN1N0_",
        "outputId": "277b15e6-ae62-48bd-c3b9-58fa5b1e44e6"
      },
      "source": [
        "def contrast():\n",
        "  #inputs = Input(shape = (128,128,3))\n",
        "  new_input = Input(shape=(224, 224, 3))\n",
        "  #model = VGG16(include_top=False, input_tensor=new_input, pooling='avg')\n",
        "  x = trip(new_input)\n",
        "  layer12 = LeakyReLU(alpha=0.3)(x)\n",
        "  layer13 = Conv2D(512,strides = 1,kernel_size=(3,3),padding=\"same\")(layer12)\n",
        "  layer5 = LeakyReLU(alpha=0.3)(layer13)\n",
        "  layer6 = Flatten()(layer5)\n",
        "  layer7 = Dense(4096,activation='relu')(layer6)\n",
        "  layer7 = Dense(4096,activation='relu')(layer7)\n",
        "  return Model(inputs = new_input,outputs = layer7)\n",
        "\n",
        "nmodel = contrast()\n",
        "nmodel.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "model (Functional)           (None, 7, 7, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)      (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 7, 7, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4096)              16781312  \n",
            "=================================================================\n",
            "Total params: 136,620,352\n",
            "Trainable params: 136,620,352\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-OGC0A_9PzN",
        "outputId": "49323a01-52c3-4474-89fd-8c8e085366cd"
      },
      "source": [
        "def triple():\n",
        "  inputs = Input(shape = (224,224,9))\n",
        "  r_i = Lambda(lambda x: x[:,:,:,0:3], name='r_i')(inputs)\n",
        "  f_i = Lambda(lambda x: x[:,:,:,3:6], name='f_i')(inputs)\n",
        "  r_j = Lambda(lambda x: x[:,:,:,6:], name='r_j')(inputs)\n",
        "  r_i = nmodel(r_i)\n",
        "  r_i = Lambda(lambda  x: K.l2_normalize(x,axis=1))(r_i)\n",
        "  f_i = nmodel(f_i)\n",
        "  f_i = Lambda(lambda  x: K.l2_normalize(x,axis=1))(f_i)\n",
        "  r_j = nmodel(r_j)\n",
        "  r_j = Lambda(lambda  x: K.l2_normalize(x,axis=1))(r_j)\n",
        "  merge_one = concatenate([r_i, f_i],axis=0)\n",
        "  merge_two = concatenate([merge_one, r_j],axis=0)\n",
        "  emb = Dense(4096)(merge_two)\n",
        "  l2_norm_final = Lambda(lambda  x: K.l2_normalize(x,axis=1))(emb)\n",
        "  return Model(inputs = inputs,outputs = l2_norm_final)\n",
        "triple_loss = triple()\n",
        "triple_loss.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 224, 224, 9) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "r_i (Lambda)                    (None, 224, 224, 3)  0           input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "f_i (Lambda)                    (None, 224, 224, 3)  0           input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "model_1 (Functional)            (None, 4096)         136620352   r_i[0][0]                        \n",
            "                                                                 f_i[0][0]                        \n",
            "                                                                 r_j[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "r_j (Lambda)                    (None, 224, 224, 3)  0           input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 4096)         0           model_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 4096)         0           model_1[1][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 4096)         0           lambda[0][0]                     \n",
            "                                                                 lambda_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 4096)         0           model_1[2][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 4096)         0           concatenate[0][0]                \n",
            "                                                                 lambda_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 4096)         16781312    concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3 (Lambda)               (None, 4096)         0           dense_2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 153,401,664\n",
            "Trainable params: 153,401,664\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ga0dSFz1rE_"
      },
      "source": [
        "_EPSILON = K.epsilon()\n",
        "def _loss_tensor(y_true, y_pred):\n",
        "  # clip to prevent NaN and Inf\n",
        "  #y_pred = K.clip(y_pred, _EPSILON, 1.0-_EPSILON)\n",
        "  loss =  tf.convert_to_tensor(0,dtype=tf.float32)\n",
        "  g = tf.constant(1.0, shape=[1], dtype=tf.float32)\n",
        "  anchor = y_pred[0,:]\n",
        "  positive =  y_pred[1,:]\n",
        "  negative = y_pred[2,:]\n",
        "  positive_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, positive)), -1)\n",
        "  negative_dist = tf.reduce_sum(tf.square(tf.subtract(anchor,negative)), -1)\n",
        "  loss_1 = tf.add(tf.subtract(positive_dist, negative_dist), 0.3)\n",
        "  loss = tf.reduce_sum(tf.maximum(loss_1, 0.0))\n",
        "  return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjWaL7ru1PvI"
      },
      "source": [
        "triple_loss.compile(loss=_loss_tensor,\n",
        " optimizer=SGD(momentum = 0.9,lr=0.001),\n",
        " metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "W2bjwOul4JVR",
        "outputId": "e46f86a5-3dd9-45db-bc15-c07081b1107b"
      },
      "source": [
        "import cv2\n",
        "import glob\n",
        "from random import randint, shuffle\n",
        "real = glob.glob(r'/content/gdrive/MyDrive/Minor_project/dataset/real/*')\n",
        "fake = glob.glob(r'/content/gdrive/MyDrive/Minor_project/dataset/fake/*')\n",
        "print(len(real))\n",
        "def read_img(fn,is_cropped = False):\n",
        "  im = cv2.imread(fn)\n",
        "  im = cv2.cvtColor(im, cv2.COLOR_BGR2LAB)\n",
        "  if is_cropped:\n",
        "    face_detector = dlib.get_frontal_face_detector()\n",
        "    detected_faces = face_detector(im, 1)\n",
        "    face_frames = [(x.left(), x.top(),x.right(), x.bottom()) for x in detected_faces]\n",
        "    face = Image.fromarray(im).crop(face_frames[0])\n",
        "    im = cv2.resize(face,(224,224),interpolation=cv2.INTER_LINEAR)\n",
        "  else:\n",
        "    im = cv2.resize(im, (224,224), interpolation=cv2.INTER_CUBIC)\n",
        "  im = np.array(im)/255*2-1\n",
        "  return im\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16361\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "n44Z34f14jY9"
      },
      "source": [
        "losses = []\n",
        "accuracies = []\n",
        "iteration_checkpoints = []\n",
        "def train(iterations,sample_interval):\n",
        "  for i in range(iterations):\n",
        "    ridx = np.random.randint(0, len(real))\n",
        "    rjdx = np.random.randint(0, len(real)) \n",
        "    while ridx == rjdx:\n",
        "      rjdx = np.random.randint(0, len(real))\n",
        "    fidx = np.random.randint(0, len(fake))\n",
        "    fjdx = np.random.randint(0, len(fake)) \n",
        "    while fidx == fjdx:\n",
        "      fjdx = np.random.randint(0, len(fake))\n",
        "    r_i = read_img(real[ridx])\n",
        "    r_j = read_img(real[rjdx])\n",
        "    f_i = read_img(fake[fidx])\n",
        "    f_j = read_img(fake[fjdx])\n",
        "    rij = np.concatenate([r_i,r_j,f_i],axis=-1)\n",
        "    fij = np.concatenate([f_i,f_j,r_i],axis=-1)\n",
        "    rfii = np.concatenate([r_i,r_j,f_j],axis=-1)\n",
        "    ffjj = np.concatenate([f_i,f_j,r_j],axis=-1)\n",
        "    #z = np.zeros((1,1))\n",
        "    one = np.ones((1,1))\n",
        "    rij = np.expand_dims(rij,axis=0)\n",
        "    fij = np.expand_dims(fij,axis=0)\n",
        "    rfii = np.expand_dims(rfii,axis=0)\n",
        "    ffjj = np.expand_dims(ffjj,axis=0)\n",
        "    lossrr,accr= triple_loss.train_on_batch(rij,one)\n",
        "    lossff,accf= triple_loss.train_on_batch(fij,one)\n",
        "    lossrf,racc = triple_loss.train_on_batch(rfii,one)\n",
        "    lossfr,facc = triple_loss.train_on_batch(ffjj,one)\n",
        "    if (i + 1) % sample_interval == 0:\n",
        "      #losses.append((lossrr, lossff,lossrf)) \n",
        "      #accuracies.append((racc,facc,accf,accr))\n",
        "      #iteration_checkpoints.append(i + 1)\n",
        "      #print(\"%d[lossrf: %f, acc.: %.2f%%] [lossrf: %f, acc.: %.2f%%]\" %(i + 1,lossrf,racc,lossfr,facc))\n",
        "      print(\"%d [lossrr: %f] [lossff: %f] [lossff: %f] [lossff: %f]\" %(i + 1, lossrr,lossff,lossfr,lossrf))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7pQd_sHJmZO",
        "outputId": "3cd70ab2-bb16-4b0b-aedd-43e5073f49fc"
      },
      "source": [
        "train(5000,50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50 [lossrr: 0.300865] [lossff: 0.300303] [lossff: 0.299597] [lossff: 0.300462]\n",
            "100 [lossrr: 0.299855] [lossff: 0.300117] [lossff: 0.299828] [lossff: 0.300074]\n",
            "150 [lossrr: 0.300498] [lossff: 0.300114] [lossff: 0.299506] [lossff: 0.300651]\n",
            "200 [lossrr: 0.300127] [lossff: 0.299293] [lossff: 0.299921] [lossff: 0.300572]\n",
            "250 [lossrr: 0.299925] [lossff: 0.299770] [lossff: 0.300288] [lossff: 0.300272]\n",
            "300 [lossrr: 0.300042] [lossff: 0.300271] [lossff: 0.300113] [lossff: 0.300208]\n",
            "350 [lossrr: 0.300096] [lossff: 0.300214] [lossff: 0.300499] [lossff: 0.299843]\n",
            "400 [lossrr: 0.299828] [lossff: 0.299911] [lossff: 0.300115] [lossff: 0.299674]\n",
            "450 [lossrr: 0.300104] [lossff: 0.299575] [lossff: 0.299529] [lossff: 0.299932]\n",
            "500 [lossrr: 0.299724] [lossff: 0.299819] [lossff: 0.299827] [lossff: 0.299776]\n",
            "550 [lossrr: 0.299918] [lossff: 0.299929] [lossff: 0.299945] [lossff: 0.299925]\n",
            "600 [lossrr: 0.300028] [lossff: 0.300405] [lossff: 0.300376] [lossff: 0.299544]\n",
            "650 [lossrr: 0.300220] [lossff: 0.300360] [lossff: 0.299974] [lossff: 0.299957]\n",
            "700 [lossrr: 0.300014] [lossff: 0.300044] [lossff: 0.300033] [lossff: 0.300030]\n",
            "750 [lossrr: 0.300097] [lossff: 0.299878] [lossff: 0.299842] [lossff: 0.300146]\n",
            "800 [lossrr: 0.299714] [lossff: 0.299804] [lossff: 0.300163] [lossff: 0.300202]\n",
            "850 [lossrr: 0.300021] [lossff: 0.299762] [lossff: 0.299971] [lossff: 0.300123]\n",
            "900 [lossrr: 0.299857] [lossff: 0.299814] [lossff: 0.299959] [lossff: 0.299836]\n",
            "950 [lossrr: 0.300003] [lossff: 0.299812] [lossff: 0.299768] [lossff: 0.300070]\n",
            "1000 [lossrr: 0.299833] [lossff: 0.300041] [lossff: 0.300020] [lossff: 0.299932]\n",
            "1050 [lossrr: 0.299688] [lossff: 0.299893] [lossff: 0.299509] [lossff: 0.299865]\n",
            "1100 [lossrr: 0.300200] [lossff: 0.300050] [lossff: 0.300017] [lossff: 0.300110]\n",
            "1150 [lossrr: 0.300093] [lossff: 0.300478] [lossff: 0.299917] [lossff: 0.300100]\n",
            "1200 [lossrr: 0.300038] [lossff: 0.300114] [lossff: 0.300200] [lossff: 0.300029]\n",
            "1250 [lossrr: 0.299630] [lossff: 0.299515] [lossff: 0.300003] [lossff: 0.299784]\n",
            "1300 [lossrr: 0.299821] [lossff: 0.300168] [lossff: 0.300006] [lossff: 0.299918]\n",
            "1350 [lossrr: 0.299663] [lossff: 0.300150] [lossff: 0.300232] [lossff: 0.299957]\n",
            "1400 [lossrr: 0.300003] [lossff: 0.299855] [lossff: 0.300205] [lossff: 0.299972]\n",
            "1450 [lossrr: 0.299676] [lossff: 0.299611] [lossff: 0.299886] [lossff: 0.299829]\n",
            "1500 [lossrr: 0.300199] [lossff: 0.300216] [lossff: 0.300406] [lossff: 0.300445]\n",
            "1550 [lossrr: 0.299698] [lossff: 0.300097] [lossff: 0.299974] [lossff: 0.299915]\n",
            "1600 [lossrr: 0.300053] [lossff: 0.300133] [lossff: 0.300110] [lossff: 0.299787]\n",
            "1650 [lossrr: 0.299918] [lossff: 0.300504] [lossff: 0.300252] [lossff: 0.299809]\n",
            "1700 [lossrr: 0.300749] [lossff: 0.300262] [lossff: 0.300195] [lossff: 0.299820]\n",
            "1750 [lossrr: 0.300234] [lossff: 0.300180] [lossff: 0.300227] [lossff: 0.299817]\n",
            "1800 [lossrr: 0.299787] [lossff: 0.300502] [lossff: 0.300768] [lossff: 0.300001]\n",
            "1850 [lossrr: 0.299599] [lossff: 0.299969] [lossff: 0.299956] [lossff: 0.299881]\n",
            "1900 [lossrr: 0.301846] [lossff: 0.305170] [lossff: 0.303519] [lossff: 0.296526]\n",
            "1950 [lossrr: 0.299995] [lossff: 0.299964] [lossff: 0.300496] [lossff: 0.299541]\n",
            "2000 [lossrr: 0.299563] [lossff: 0.298766] [lossff: 0.300022] [lossff: 0.299001]\n",
            "2050 [lossrr: 0.301711] [lossff: 0.298949] [lossff: 0.299286] [lossff: 0.302482]\n",
            "2100 [lossrr: 0.300096] [lossff: 0.300571] [lossff: 0.300245] [lossff: 0.299794]\n",
            "2150 [lossrr: 0.298872] [lossff: 0.301754] [lossff: 0.304213] [lossff: 0.299183]\n",
            "2200 [lossrr: 0.301563] [lossff: 0.302086] [lossff: 0.300939] [lossff: 0.299329]\n",
            "2250 [lossrr: 0.299415] [lossff: 0.300055] [lossff: 0.300183] [lossff: 0.300010]\n",
            "2300 [lossrr: 0.299593] [lossff: 0.299870] [lossff: 0.300334] [lossff: 0.300273]\n",
            "2350 [lossrr: 0.300064] [lossff: 0.300786] [lossff: 0.300771] [lossff: 0.299486]\n",
            "2400 [lossrr: 0.299896] [lossff: 0.300026] [lossff: 0.300329] [lossff: 0.300239]\n",
            "2450 [lossrr: 0.300104] [lossff: 0.300197] [lossff: 0.300235] [lossff: 0.299755]\n",
            "2500 [lossrr: 0.300212] [lossff: 0.300394] [lossff: 0.300708] [lossff: 0.300360]\n",
            "2550 [lossrr: 0.299502] [lossff: 0.298483] [lossff: 0.299555] [lossff: 0.299739]\n",
            "2600 [lossrr: 0.300382] [lossff: 0.300300] [lossff: 0.300691] [lossff: 0.298774]\n",
            "2650 [lossrr: 0.300440] [lossff: 0.299601] [lossff: 0.300269] [lossff: 0.299971]\n",
            "2700 [lossrr: 0.299623] [lossff: 0.300031] [lossff: 0.299784] [lossff: 0.299779]\n",
            "2750 [lossrr: 0.299950] [lossff: 0.299734] [lossff: 0.299901] [lossff: 0.299859]\n",
            "2800 [lossrr: 0.301413] [lossff: 0.299033] [lossff: 0.299524] [lossff: 0.301531]\n",
            "2850 [lossrr: 0.301875] [lossff: 0.300559] [lossff: 0.297826] [lossff: 0.301554]\n",
            "2900 [lossrr: 0.300190] [lossff: 0.300706] [lossff: 0.300318] [lossff: 0.299711]\n",
            "2950 [lossrr: 0.300233] [lossff: 0.297277] [lossff: 0.289467] [lossff: 0.292307]\n",
            "3000 [lossrr: 0.299460] [lossff: 0.300691] [lossff: 0.301433] [lossff: 0.300520]\n",
            "3050 [lossrr: 0.300303] [lossff: 0.300750] [lossff: 0.300086] [lossff: 0.299616]\n",
            "3100 [lossrr: 0.300465] [lossff: 0.300536] [lossff: 0.300338] [lossff: 0.299496]\n",
            "3150 [lossrr: 0.299571] [lossff: 0.300067] [lossff: 0.299915] [lossff: 0.300050]\n",
            "3200 [lossrr: 0.300442] [lossff: 0.301849] [lossff: 0.301297] [lossff: 0.298569]\n",
            "3250 [lossrr: 0.300502] [lossff: 0.300109] [lossff: 0.300217] [lossff: 0.300330]\n",
            "3300 [lossrr: 0.300080] [lossff: 0.300032] [lossff: 0.299821] [lossff: 0.300810]\n",
            "3350 [lossrr: 0.300019] [lossff: 0.300121] [lossff: 0.300292] [lossff: 0.300218]\n",
            "3400 [lossrr: 0.300274] [lossff: 0.300252] [lossff: 0.299889] [lossff: 0.299772]\n",
            "3450 [lossrr: 0.299844] [lossff: 0.299664] [lossff: 0.299665] [lossff: 0.299776]\n",
            "3500 [lossrr: 0.299515] [lossff: 0.300146] [lossff: 0.300014] [lossff: 0.300149]\n",
            "3550 [lossrr: 0.299764] [lossff: 0.299214] [lossff: 0.300028] [lossff: 0.299994]\n",
            "3600 [lossrr: 0.299844] [lossff: 0.300578] [lossff: 0.300172] [lossff: 0.299474]\n",
            "3650 [lossrr: 0.299699] [lossff: 0.299747] [lossff: 0.299985] [lossff: 0.299635]\n",
            "3700 [lossrr: 0.299931] [lossff: 0.299956] [lossff: 0.300467] [lossff: 0.299893]\n",
            "3750 [lossrr: 0.299772] [lossff: 0.299757] [lossff: 0.300350] [lossff: 0.298317]\n",
            "3800 [lossrr: 0.299848] [lossff: 0.299869] [lossff: 0.299502] [lossff: 0.299708]\n",
            "3850 [lossrr: 0.301130] [lossff: 0.299791] [lossff: 0.299137] [lossff: 0.301043]\n",
            "3900 [lossrr: 0.298263] [lossff: 0.298727] [lossff: 0.299440] [lossff: 0.299859]\n",
            "3950 [lossrr: 0.299317] [lossff: 0.298643] [lossff: 0.295379] [lossff: 0.300081]\n",
            "4000 [lossrr: 0.318136] [lossff: 0.295882] [lossff: 0.261058] [lossff: 0.254908]\n",
            "4050 [lossrr: 0.297788] [lossff: 0.299623] [lossff: 0.302302] [lossff: 0.296652]\n",
            "4100 [lossrr: 0.298983] [lossff: 0.286025] [lossff: 0.305660] [lossff: 0.313167]\n",
            "4150 [lossrr: 0.299174] [lossff: 0.298461] [lossff: 0.305861] [lossff: 0.301437]\n",
            "4200 [lossrr: 0.291109] [lossff: 0.290689] [lossff: 0.290724] [lossff: 0.292916]\n",
            "4250 [lossrr: 0.300930] [lossff: 0.302563] [lossff: 0.298743] [lossff: 0.304462]\n",
            "4300 [lossrr: 0.297486] [lossff: 0.297574] [lossff: 0.301436] [lossff: 0.301060]\n",
            "4350 [lossrr: 0.299898] [lossff: 0.302774] [lossff: 0.302741] [lossff: 0.295540]\n",
            "4400 [lossrr: 0.300378] [lossff: 0.294230] [lossff: 0.299926] [lossff: 0.297606]\n",
            "4450 [lossrr: 0.302462] [lossff: 0.301420] [lossff: 0.298556] [lossff: 0.300431]\n",
            "4500 [lossrr: 0.300360] [lossff: 0.303347] [lossff: 0.303797] [lossff: 0.297607]\n",
            "4550 [lossrr: 0.306249] [lossff: 0.296989] [lossff: 0.296878] [lossff: 0.306658]\n",
            "4600 [lossrr: 0.301757] [lossff: 0.301976] [lossff: 0.299247] [lossff: 0.300798]\n",
            "4650 [lossrr: 0.300337] [lossff: 0.315118] [lossff: 0.312804] [lossff: 0.279167]\n",
            "4700 [lossrr: 0.301274] [lossff: 0.300257] [lossff: 0.301263] [lossff: 0.299724]\n",
            "4750 [lossrr: 0.298267] [lossff: 0.298369] [lossff: 0.298761] [lossff: 0.298661]\n",
            "4800 [lossrr: 0.300642] [lossff: 0.303329] [lossff: 0.302767] [lossff: 0.297063]\n",
            "4850 [lossrr: 0.301149] [lossff: 0.305305] [lossff: 0.299089] [lossff: 0.301341]\n",
            "4900 [lossrr: 0.298168] [lossff: 0.301487] [lossff: 0.301799] [lossff: 0.299862]\n",
            "4950 [lossrr: 0.302134] [lossff: 0.304214] [lossff: 0.298257] [lossff: 0.298289]\n",
            "5000 [lossrr: 0.301297] [lossff: 0.298209] [lossff: 0.299331] [lossff: 0.304576]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oK0wQQGzEVaM"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "maN1WaVNtFwn"
      },
      "source": [
        "def hello():\n",
        "  inputs = Input(shape=(224,224,6))\n",
        "  r_i = nmodel(inputs[:,:,:,0:3])\n",
        "  r_j = nmodel(inputs[:,:,:,3:])\n",
        "  score = tf.reduce_sum(tf.square(tf.subtract(r_i, r_j)), -1)\n",
        "  outputs = Activation('sigmoid')(score)\n",
        "  return Model(inputs=inputs,outputs = outputs)\n",
        "embed = hello()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "53RB01Uru4Dm",
        "outputId": "7f3ce493-1fd9-476e-8c3b-31b822c0b5f9"
      },
      "source": [
        "fk = read_img('/content/testfake.PNG')\n",
        "fk = np.expand_dims(fk,axis=0)\n",
        "for i in range(20):\n",
        "  ridx = np.random.randint(0, len(fake))\n",
        "  r_i = read_img(fake[ridx])\n",
        "  rij = np.expand_dims(r_i,axis=0)\n",
        "  rij = np.concatenate([rij,fk],axis=-1)\n",
        "  print(embed.predict(rij))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-78e6cc5a1f66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/testfake.PNG'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mridx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mr_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mridx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'read_img' is not defined"
          ]
        }
      ]
    }
  ]
}